{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spaceship Titanic Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries and dataset\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "\n",
    "# Function to impute mean or median based on skewness\n",
    "def impute_with_mean_or_median(column):\n",
    "    skewness = df[column].skew()\n",
    "    if abs(skewness) > 1:\n",
    "        median = df[column].median()\n",
    "        return df[column].fillna(median)\n",
    "    media = round(df[column].mean())\n",
    "    return df[column].fillna(media)\n",
    "\n",
    "# Function to impute mode based on the most frequent value\n",
    "def mode_impute(column):\n",
    "    moda_val = df[column].mode()[0]\n",
    "    return df[column].fillna(moda_val)\n",
    "\n",
    "# Binarize the booleans\n",
    "df['CryoSleep'] = df['CryoSleep'].replace({False: 0, True: 1})\n",
    "df['VIP'] = df['VIP'].replace({False: 0, True: 1})\n",
    "df['Transported'] = df['Transported'].replace({False: 0, True: 1})\n",
    "\n",
    "# I: Create new columns\n",
    "# Passenger Id: Divide into group and passenger number\n",
    "df[['GroupNum', 'PassNum']] = df['PassengerId'].str.split('_', expand=True)\n",
    "df['GroupNum'] = pd.to_numeric(df['GroupNum'], errors='coerce')\n",
    "df['PassNum'] = pd.to_numeric(df['PassNum'], errors='coerce')\n",
    "df.drop(columns=[\"PassengerId\"], inplace=True)\n",
    "# TotalSpent: Total spent on amenities\n",
    "df['TotalSpent'] = df[[\"RoomService\", \"FoodCourt\", \"ShoppingMall\", \"Spa\", \"VRDeck\"]].sum(axis=1)\n",
    "# Cabin column: Divide in three: Deck, CabinNumber, CabinSide\n",
    "df[['Deck', 'CabinNumber', 'CabinSide']] = df['Cabin'].str.split('/', expand=True)\n",
    "df.drop(columns=[\"Cabin\"], inplace=True)\n",
    "\n",
    "# II: Label encoding for categorical data\n",
    "df['HomePlanet'] = df['HomePlanet'].replace({'Earth': 0, 'Mars': 1, 'Europa': 2})\n",
    "df['Destination'] = df['Destination'].replace({'TRAPPIST-1e': 0, '55 Cancri e': 1, 'PSO J318.5-22': 2})\n",
    "df['Deck'] = df['Deck'].replace({'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'T': 7})\n",
    "df['CabinSide'] = df['CabinSide'].replace({'P': 0, 'S': 1})\n",
    "\n",
    "# III: Special cases for missing categorical values\n",
    "# **Deck: (6 if HomePlanet == 0 and Deck is null)\n",
    "df.loc[(df['HomePlanet'] == 0) & (df['Deck'].isnull()), 'Deck'] = 6 # Deck 6 is for passengers from Earth\n",
    "# **CryoSleep: (0 if TotalSpent != 0)\n",
    "df.loc[(df['TotalSpent'] > 0) & (df['CryoSleep'].isnull()), 'CryoSleep'] = 0 # If a passenger has spent money, then they did not use Cryosleep\n",
    "# **VIP: If CryoSleep is 1 then 0, else impute mode\n",
    "df.loc[(df['CryoSleep'] == 1) & (df['VIP'].isnull()), 'VIP'] = 0 # If a passenger is in Cryosleep, then they're not VIP\n",
    "\n",
    "# IV: Impute categorical data with mode\n",
    "df['HomePlanet'] = mode_impute('HomePlanet')\n",
    "df['Destination'] = mode_impute('Destination')\n",
    "df['Deck'] = mode_impute('Deck')\n",
    "df['CabinSide'] = mode_impute('CabinSide')\n",
    "df['CryoSleep'] = mode_impute('CryoSleep')\n",
    "df['VIP'] = mode_impute('VIP')\n",
    "\n",
    "# V: Create interaction columns\n",
    "# HomePlanet-Destination: Bin the HomePlanet and Destination columns\n",
    "df['HomePlanet_Destination_Interaction'] = df['HomePlanet'] * df['Destination']\n",
    "# Deck-CabinSide: Bin the Deck and CabinSide columns\n",
    "\n",
    "\n",
    "# VI: Special cases for missing numerical values\n",
    "# **Amennities: (0 if CryoSleep == 1)\n",
    "amenities = [\"RoomService\", \"FoodCourt\", \"ShoppingMall\", \"Spa\", \"VRDeck\"]\n",
    "for amenity in amenities:\n",
    "    df.loc[(df['CryoSleep'] == 1) & (df[amenity].isnull()), amenity] = 0 # If a passenger is in Cryosleep, then they did not use any amenities\n",
    "# **Age: (6 if TotalSpent == 0)\n",
    "df.loc[(df['TotalSpent'] == 0) & (df['Age'].isnull()), 'Age'] = 6 # If a passenger has not spent any money, then they're likely a child. 6 is the mean age of non-spdender children\n",
    "\n",
    "# VII: Impute numerical data with mean or median\n",
    "df['RoomService'] = impute_with_mean_or_median('RoomService')\n",
    "df['FoodCourt'] = impute_with_mean_or_median('FoodCourt')\n",
    "df['ShoppingMall'] = impute_with_mean_or_median('ShoppingMall')\n",
    "df['Spa'] = impute_with_mean_or_median('Spa')\n",
    "df['VRDeck'] = impute_with_mean_or_median('VRDeck')\n",
    "df['CabinNumber'] = pd.to_numeric(df['CabinNumber'], errors='coerce') # Convert CabinNumber to numeric\n",
    "df['CabinNumber'] = impute_with_mean_or_median('CabinNumber')\n",
    "df['Age'] = impute_with_mean_or_median('Age')\n",
    "\n",
    "# VIII: Drop unnecessary columns\n",
    "df.drop(columns=[\"Name\"], inplace=True)\n",
    "\n",
    "# IX: Standarize the data\n",
    "X = df.drop(columns=['Transported'])\n",
    "y = df['Transported']\n",
    "means = X.mean()\n",
    "std_devs = X.std()\n",
    "X_standardized = (X - means) / std_devs\n",
    "df = pd.concat([X_standardized, y], axis=1)\n",
    "\n",
    "# Ensure all columns are numeric\n",
    "df = df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Save cleaned dataset as csv | Optional\n",
    "df.to_csv('clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Split dataset into train and test sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=13)\n",
    "\n",
    "\n",
    "# Import models for Random Forest, Logistic Regression, and XGBoost\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Base models\n",
    "cb = CatBoostClassifier(random_state=13, verbose=0)\n",
    "svm = SVC(random_state=13)\n",
    "lgbm = LGBMClassifier(random_state=13, force_row_wise=True, verbose = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost:\n",
      "Accuracy: 0.8136860264519838\n",
      "Precision: 0.8036322360953462\n",
      "Recall: 0.8242142025611175\n",
      "F1 Score: 0.8137931034482758\n",
      "\n",
      "SVM:\n",
      "Accuracy: 0.7855089131684876\n",
      "Precision: 0.7318702290076335\n",
      "Recall: 0.8928987194412107\n",
      "F1 Score: 0.8044048243314106\n",
      "\n",
      "LightGBM:\n",
      "Accuracy: 0.8096607245543416\n",
      "Precision: 0.7972972972972973\n",
      "Recall: 0.8242142025611175\n",
      "F1 Score: 0.8105323411562679\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate base models\n",
    "models = [cb, svm, lgbm]\n",
    "model_names = ['CatBoost', 'SVM', 'LightGBM']\n",
    "for model, name in zip(models, model_names):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    print(f'{name}:\\nAccuracy: {accuracy}\\nPrecision: {precision}\\nRecall: {recall}\\nF1 Score: {f1}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'depth': 8, 'l2_leaf_reg': 1, 'learning_rate': 0.01}\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning for CatBoost\n",
    "param_grid = {\n",
    "    'depth': [6, 8, 10],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'l2_leaf_reg': [1, 3, 6, 9]\n",
    "}\n",
    "cb_grid = GridSearchCV(cb, param_grid, cv=5, n_jobs=-1, verbose=0)\n",
    "cb_grid.fit(X_train, y_train)\n",
    "print(cb_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "# SVM hyperparameter tuning\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'gamma': [0.1, 0.01, 0.001],\n",
    "    'kernel': ['rbf', 'sigmoid']\n",
    "}\n",
    "svm_grid = GridSearchCV(svm, param_grid, cv=5, n_jobs=-1, verbose=0)\n",
    "svm_grid.fit(X_train, y_train)\n",
    "print(svm_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 1, 'force_row_wise': True, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 200, 'subsample': 0.5}\n"
     ]
    }
   ],
   "source": [
    "# Light GBM\n",
    "lgbm_params = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 3, 6, 9],\n",
    "    'learning_rate': [0.01, 0.1, 0.3],\n",
    "    'subsample': [0.5, 0.7, 1],\n",
    "    'colsample_bytree': [0.5, 0.7, 1],\n",
    "    'force_row_wise': [True, False]\n",
    "}\n",
    "lgbm_grid = GridSearchCV(lgbm, lgbm_params, cv=5, n_jobs=-1)\n",
    "lgbm_grid.fit(X_train, y_train)\n",
    "print(lgbm_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost:\n",
      "Accuracy: 0.8090856814261069\n",
      "Precision: 0.7957351290684624\n",
      "Recall: 0.8253783469150174\n",
      "F1 Score: 0.8102857142857143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict with best parameters for CatBoost\n",
    "cb_best = CatBoostClassifier(random_state=13, verbose=0, **cb_grid.best_params_)\n",
    "cb_best.fit(X_train, y_train)\n",
    "y_pred = cb_best.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f'CatBoost:\\nAccuracy: {accuracy}\\nPrecision: {precision}\\nRecall: {recall}\\nF1 Score: {f1}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM:\n",
      "Accuracy: 0.7199539965497412\n",
      "Precision: 0.8333333333333334\n",
      "Recall: 0.5413271245634459\n",
      "F1 Score: 0.656316160903317\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict with best parameters for SVM\n",
    "svm_best = SVC(random_state=13, **svm_grid.best_params_)\n",
    "svm_best.fit(X_train, y_train)\n",
    "y_pred = svm_best.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f'SVM:\\nAccuracy: {accuracy}\\nPrecision: {precision}\\nRecall: {recall}\\nF1 Score: {f1}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Light GBM:\n",
      "Accuracy: 0.8113858539390454\n",
      "Precision: 0.8020477815699659\n",
      "Recall: 0.8207217694994179\n",
      "F1 Score: 0.8112773302646721\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict with best parameters for Light GBM\n",
    "lgbm_best = lgbm_grid.best_estimator_\n",
    "lgbm_best.fit(X_train, y_train)\n",
    "y_pred = lgbm_best.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f'Light GBM:\\nAccuracy: {accuracy}\\nPrecision: {precision}\\nRecall: {recall}\\nF1 Score: {f1}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the test set with 100% of the data and save it as a csv\n",
    "df = pd.read_csv(\"test.csv\")\n",
    "cb_best.fit(X, y)\n",
    "\n",
    "# Repeat the same data cleaning steps for the test set\n",
    "\n",
    "# Function to impute mean or median based on skewness\n",
    "def impute_with_mean_or_median(column):\n",
    "    skewness = df[column].skew()\n",
    "\n",
    "    if abs(skewness) > 1:\n",
    "        mediana = df[column].median()\n",
    "        return df[column].fillna(mediana)\n",
    "    \n",
    "    media = round(df[column].mean())\n",
    "    return df[column].fillna(media)\n",
    "\n",
    "# Function to impute mode based on the most frequent value\n",
    "def mode_impute(column):\n",
    "    moda_val = df[column].mode()[0]\n",
    "    return df[column].fillna(moda_val)\n",
    "\n",
    "# Binarize the booleans\n",
    "df['CryoSleep'] = df['CryoSleep'].replace({False: 0, True: 1})\n",
    "df['VIP'] = df['VIP'].replace({False: 0, True: 1})\n",
    "#df['Transported'] = df['Transported'].replace({False: 0, True: 1})\n",
    "\n",
    "# I: Create new columns\n",
    "# Passenger Id: Divide into group and passenger number\n",
    "df[['GroupNum', 'PassNum']] = df['PassengerId'].str.split('_', expand=True)\n",
    "df['GroupNum'] = pd.to_numeric(df['GroupNum'], errors='coerce')\n",
    "df['PassNum'] = pd.to_numeric(df['PassNum'], errors='coerce')\n",
    "df.drop(columns=[\"PassengerId\"], inplace=True)\n",
    "# TotalSpent: Total spent on amenities\n",
    "df['TotalSpent'] = df[[\"RoomService\", \"FoodCourt\", \"ShoppingMall\", \"Spa\", \"VRDeck\"]].sum(axis=1)\n",
    "# Cabin column: Divide in three: Deck, CabinNumber, CabinSide\n",
    "df[['Deck', 'CabinNumber', 'CabinSide']] = df['Cabin'].str.split('/', expand=True)\n",
    "df.drop(columns=[\"Cabin\"], inplace=True)\n",
    "\n",
    "# II: Label encoding for categorical data\n",
    "df['HomePlanet'] = df['HomePlanet'].replace({'Earth': 0, 'Mars': 1, 'Europa': 2})\n",
    "df['Destination'] = df['Destination'].replace({'TRAPPIST-1e': 0, '55 Cancri e': 1, 'PSO J318.5-22': 2})\n",
    "df['Deck'] = df['Deck'].replace({'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'T': 7})\n",
    "df['CabinSide'] = df['CabinSide'].replace({'P': 0, 'S': 1})\n",
    "\n",
    "# III: Special cases for missing categorical values\n",
    "# **Deck: (6 if HomePlanet == 0 and Deck is null)\n",
    "df.loc[(df['HomePlanet'] == 0) & (df['Deck'].isnull()), 'Deck'] = 6 # Deck 6 is for passengers from Earth\n",
    "# **CryoSleep: (0 if TotalSpent != 0)\n",
    "df.loc[(df['TotalSpent'] > 0) & (df['CryoSleep'].isnull()), 'CryoSleep'] = 0 # If a passenger has spent money, then they did not use Cryosleep\n",
    "# **VIP: If CryoSleep is 1 then 0, else impute mode\n",
    "df.loc[(df['CryoSleep'] == 1) & (df['VIP'].isnull()), 'VIP'] = 0 # If a passenger is in Cryosleep, then they're not VIP\n",
    "\n",
    "# IV: Impute categorical data with mode\n",
    "df['HomePlanet'] = mode_impute('HomePlanet')\n",
    "df['Destination'] = mode_impute('Destination')\n",
    "df['Deck'] = mode_impute('Deck')\n",
    "df['CabinSide'] = mode_impute('CabinSide')\n",
    "df['CryoSleep'] = mode_impute('CryoSleep')\n",
    "df['VIP'] = mode_impute('VIP')\n",
    "\n",
    "# V: Create interaction columns\n",
    "# HomePlanet-Destination: Bin the HomePlanet and Destination columns\n",
    "df['HomePlanet_Destination_Interaction'] = df['HomePlanet'] * df['Destination']\n",
    "# Deck-Cabin\n",
    "\n",
    "# VI: Special cases for missing numerical values\n",
    "# **Amennities: (0 if CryoSleep == 1)\n",
    "amenities = [\"RoomService\", \"FoodCourt\", \"ShoppingMall\", \"Spa\", \"VRDeck\"]\n",
    "for amenity in amenities:\n",
    "    df.loc[(df['CryoSleep'] == 1) & (df[amenity].isnull()), amenity] = 0 # If a passenger is in Cryosleep, then they did not use any amenities\n",
    "# **Age: (6 if TotalSpent == 0)\n",
    "df.loc[(df['TotalSpent'] == 0) & (df['Age'].isnull()), 'Age'] = 6 # If a passenger has not spent any money, then they're likely a child. 6 is the mean age of non-spdender children\n",
    "\n",
    "# VII: Impute numerical data with mean or median\n",
    "df['RoomService'] = impute_with_mean_or_median('RoomService')\n",
    "df['FoodCourt'] = impute_with_mean_or_median('FoodCourt')\n",
    "df['ShoppingMall'] = impute_with_mean_or_median('ShoppingMall')\n",
    "df['Spa'] = impute_with_mean_or_median('Spa')\n",
    "df['VRDeck'] = impute_with_mean_or_median('VRDeck')\n",
    "df['CabinNumber'] = pd.to_numeric(df['CabinNumber'], errors='coerce') # Convert CabinNumber to numeric\n",
    "df['CabinNumber'] = impute_with_mean_or_median('CabinNumber')\n",
    "df['Age'] = impute_with_mean_or_median('Age')\n",
    "\n",
    "# VIII: Drop unnecessary columns\n",
    "df.drop(columns=[\"Name\"], inplace=True)\n",
    "\n",
    "# IX: Standarize the data\n",
    "# The dataset is standardized\n",
    "df_standardized = (df - df.mean()) / df.std()\n",
    "\n",
    "# Ensure all columns are numeric\n",
    "df = df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Save cleaned dataset as csv | Optional\n",
    "df.to_csv('clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training and csv submission (Create Transported column and predict using the best model)\n",
    "y_pred = cb_best.predict(df)\n",
    "#y_pred = svm_best.predict(df)\n",
    "#y_pred = lgbm_best.predict(df)\n",
    "\n",
    "# Generate submission csv with PassengerId (once removed for data cleaning) and Transported columns only\n",
    "submission = pd.read_csv(\"test.csv\")\n",
    "submission['Transported'] = y_pred\n",
    "submission = submission[['PassengerId', 'Transported']]\n",
    "# Transform boolean values to strings\n",
    "submission['Transported'] = submission['Transported'].replace({0: 'False', 1: 'True'})\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store model using pickle\n",
    "import pickle\n",
    "filename = 'finalized_model.sav'\n",
    "pickle.dump(cb_best, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8694652098907418\n"
     ]
    }
   ],
   "source": [
    "#Load the model from disk (Pickle)\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "result = loaded_model.score(X_test, y_test)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
